# 架构的目的

架构设计的主要目的是为了解决软件系统**复杂度（重点）**带来的问题。

复杂度有时候是个相对的概念，因为人类无法治理过于复杂的单个事物，因此需要将其拆分。也就是说，如果有人可以凭一己之力处理复杂事物（例如Linus Torvalds可以单个人写出一个正确的宏内核），此时就无需分解了（当然微服务架构除了降低单体的复杂性外还有水平扩展的原因）。

# 复杂度的来源

* 高性能：因为扩展性能而带来的复杂性（多线程->多进程->集群）
* 高可用：因为扩展冗余而带来的复杂性（todo：三种）
* 扩展性
* 低成本、安全、规模

因此做架构设计流程的第一步就是识别权重最高的复杂度。值得一提的是《ddia》在开篇中也提出了类似的观点。

# 架构设计的三大原则

* 合适优于业界领先（权衡的标准是从实际业务出发）
* 简单优于复杂
* 演化优于一步到位

# 架构设计的流程

* 识别复杂度：是上述三种中的哪一种
* 设计备选方案：应用上述的架构原则
* 评估和选择：对比优劣，进行**取舍**
* 设计详细方案：todo

# 复杂度：高性能架构模式

通过系统中4个方面来描述高性能架构模式
* 数据库，包括NoSQL
* 缓存
* 负载均衡
* 单机计算能力

这里只讨论数据库，其它方面todo

## 高性能数据库集群

注意原文用的是集群两个字，实际上我觉得这里应该是分布式

* 读写分离（数据还是在一个DB）
* 分库分表（数据分摊到不同的DB）

原则是通过各种手段分担单机的压力

> **注意这里必须与下面的高可用存储架构模式区别**



# 复杂度：高可用架构模式

## CAP原理：

* C：对某个指定的客户端来说，读操作保证能够返回最新的写操作结果
  * 从**客户端**的角度来理解，强调client读取到的是最新写入的已提交的数据，似乎是线性一致性？
  * 不强调同一时刻拥有相同的数据！因为在事务执行过程中，系统其实处于一个不一致的状态，不同的节点的数据并不完全一致
  * 关于一致性的各种分类：https://cloud.tencent.com/developer/article/1015442
  
* A：非故障的节点在**合理的时间**内返回**合理的响应**
  * 合理的时间指**不超时**
  * 合理的响应指不报错（例如返回500拒绝服务，**注意500报错和友善的客户端报错不是同一回事**，个人认为如果出现500或者服务直接不能用是没有区别的），但是可以是不正确的数据（例如因为分区导致的数据不一致的陈旧数据）
  
* P：当出现网络分区后，系统能够继续“履行职责”
  * 履行职责指不报错，不拒绝服务。个人认为这里关于P的定义和A有点混淆不清。个人的理解是当网络分区之后系统依然对外服务，对外服务可以选择A或C两种模式。当选择A模式的时候对外提供的数据可能是过时的，**（此时所有脑裂的分区依然运作？）**；当选择C模式的时候是直接返回友好的提示说系统某些功能为了一致性暂时不能用，但是能提供一些基础的浏览服务之类（又或者只有部分脑裂的分区能够继续提供读写服务，其它脑裂分区停止服务？）。
  
  根据这里https://blog.csdn.net/chen77716/article/details/30635543，A强调的是对所有客户端的请求都有回应，而P强调的时候"系统可用"。"系统可用"这个概念的范围非常广：
  
  * 情况1：系统对**所有**client的请求都有响应，但此时不能满足C；
  * 系统对**部分**client的请求有响应，但此时不能满足A；



## CAP细节

* CAP 关注的粒度是数据，而不是整个系统：所以在 CAP 理论落地实践时，我们需要将系统内的数据按照不同的应用场景和要求进行分类，每类数据选择不同的策略（CP 还是 AP），而不是直接限定整个系统所有数据都是同一策略。
* CAP是忽略网络延迟的
* 正常运行情况下，不存在 CP 和 AP 的选择，可以同时满足 CA

## 高可用通用原则

* 奔溃前：减轻压力，防止奔溃
  * 负载均衡
  * 限流
  * 熔断
* 奔溃后：自动的故障转移，涉及：
  * 数据冗余和同步的方案
  * 奔溃后的自动选择方案

## 高可用存储架构

**存储高可用的本质是冗余，其复杂性是同步数据时的一致性问题**（延迟、网络中断导致）。需要注意的是它和业务高可用的区别。

按照单机是否存储所有数据，高可用可以分为以下两种类型：

* 双机模式（单机存储所有的数据）

  | 类型     | 优点 | 缺点 |
  | -------- | ---- | ---- |
  | 主备复制 |      |      |
  | 主从复制 |      |      |
  | 双机切换 |      |      |
  | 主主复制 |      |      |

  其实这个双机集群机制是N机模式的弱化版，两者面对的复杂性都是一样的，只是程度不同而已。需要面对的问题包括：

  * 数据如何复制
  * 主机状态的检测
  * 主机故障后如何选定新主机（paxos、raft等一致性协议）

* 分区（单机不能存储所有的数据）

  感觉就是数据分片到节点，各个节点再做集群。复杂性是数据分片的一般性问题（todo）

## 高可用业务架构

* 防止业务奔溃

  * 负载均衡
  * 限流
  * 熔断

* 奔溃后的方案

  * 业务通常是不带状态的，因此可以简单地用集群中的对等节点取代之。

  * 如果业务也有状态，则将业务的状态委托给存储即可。

总之都可以用k8s搞定

# 复杂度：可扩展架构模式

## 核心思想：

拆！即分层或者模块化，然后针对需要扩展的模块独立修改。

## 各种拆分方式的比较

| 类型     | 例子                         | 优点 | 缺点 |
| -------- | ---------------------------- | ---- | ---- |
| 面向流程 | 分层架构                     |      |      |
| 面向服务 | 微服务、SOA                  |      |      |
| 面向功能 | 微内核（插件机制，规则引擎） |      |      |

以上几种方式可以组合一起使用，对系统的各个维度进行划分，例如：

- 例如用微服务划分系统
- 每个微服务又划分为多个流程
- 每个流程用微内核实现

