# 架构的目的

架构设计的主要目的是为了解决软件系统**复杂度（重点）**带来的问题。

复杂度有时候是个相对的概念，因为人类无法治理过于复杂的单个事物，因此需要将其拆分。也就是说，如果有人可以凭一己之力处理复杂事物（例如Linus Torvalds可以单个人写出一个正确的宏内核），此时就无需分解了（当然微服务架构除了降低单体的复杂性外还有水平扩展的原因）。

# 复杂度的来源

* 高性能：因为扩展性能而带来的复杂性（多线程->多进程->集群）
* 高可用：因为扩展冗余而带来的复杂性（todo：三种）
* 扩展性
* 低成本、安全、规模

因此做架构设计流程的第一步就是识别权重最高的复杂度。值得一提的是《ddia》在开篇中也提出了类似的观点。

# 架构设计的三大原则

* 合适优于业界领先（权衡的标准是从实际业务出发）
* 简单优于复杂
* 演化优于一步到位

# 架构设计的流程

* 识别复杂度：是上述三种中的哪一种
* 设计备选方案：应用上述的架构原则
* 评估和选择：对比优劣，进行**取舍**
* 设计详细方案：todo

# 复杂度：高性能架构模式

通过系统中4个方面来描述高性能架构模式
* 高性能RMDB集群（通用型数据库的高性能手段）
* 高性能NoSQL（特殊场景下使用NoSQL来应对特殊需求）
* 缓存
* 负载均衡
* 单机计算能力

这里只讨论数据库，其它方面todo

## 高性能RMDB集群

注意原文用的是集群两个字，实际上我觉得这里应该是分布式

* **读写分离**（数据还是在一个DB）
* **分库分表**（数据分摊到不同的DB）

原则是通过各种手段分担单机的压力

> **注意与下面的高可用存储架构模式区别，高可用的本质是冗余，高性能的本质是摊分。**



读写分离需要面对的问题

| 问题                                             | 解决方案                                                     |
| ------------------------------------------------ | ------------------------------------------------------------ |
| 主从复制延迟                                     | 1，写操作后的读需要发到主服务器，即粘性会话机制<br>2，读从机失败后再读取一次主机，即二次读取<br>3，关键业务的读写指向主机，非关键业务采用读写分离 |
| 分配机制<br>(将读写区分开来然后发送给不同的机器) | 1，程序代码封装<br>2，中间件封装                             |





# 复杂度：高可用架构模式

## CAP原理：

* C：对某个指定的客户端来说，读操作保证能够返回最新的写操作结果
  * 从**客户端**的角度来理解，强调client读取到的是最新写入的已提交的数据，似乎是线性一致性？
  
  * 不强调同一时刻拥有相同的数据！因为在事务执行过程中，系统其实处于一个不一致的状态，不同的节点的数据并不完全一致
  
  * 关于一致性的各种分类：https://writings.sh/post/cap-and-consistency-models
  
    从上到下，要求依次提高，每一个下层的一致性模型都是在上层的一致性模型上减少了某些约束
  
    * 严格一致性：无法实现
  
    * 强一致性：
      * 线性一致性：
      * 顺序一致性：
  
    * 弱一致性
      * 因果一致性：
      * 单调一致性：
      * 最终一致性：
  
    
  
* A：**对所有请求**，系统都必须在**合理的时间**内返回**合理的响应**
  * 合理的时间指**不超时**
  * 合理的响应指不报错（例如返回500拒绝服务，**注意500报错和友善的客户端报错提示不是同一回事**，个人认为出现500和服务直接不能用是没有区别的），但是可以是不正确的数据（例如因为分区导致的数据不一致的陈旧数据）
  
* P：当出现网络分区后，系统能够继续“履行职责”
  
  这里关键需要区分P和A有什么不同，摘抄一段知乎的答案，这个答案表明为了保证C，系统此时可能只是部分可用。例如可能是全部节点只提供读功能；又或者部分节点提供读写功能，剩下的节点不可用。
  
  >**分区容忍就是指分布式系统在出现网络分区的时候，仍然能继续运行，对外提供服务。**注意，这里所说的仍然能够对外提供服务跟可用性的要求不一样，可用性要求的是对于任意请求都能得到响应，意味着即使出现网络分区所有节点都能够提供服务。而分区容忍的重点在于出现网络分区之后，**系统仍然是可用的（包括部分可用）**。
  >
  >链接：https://www.zhihu.com/question/54105974/answer/2144019181







## CAP细节

* **CAP 关注的粒度是数据，而不是整个系统**：所以在 CAP 理论落地实践时，我们需要将系统内的数据按照不同的应用场景和要求进行分类，每类数据选择不同的策略（CP 还是 AP），而不是直接限定整个系统所有数据都是同一策略。
* CAP是忽略网络延迟的
* 正常运行情况下，不存在 CP 和 AP 的选择，可以同时满足 CAP

## 高可用通用原则

* 奔溃前：减轻压力，防止奔溃
  * 负载均衡
  * 限流
  * 熔断
* 奔溃后：自动的故障转移，涉及：
  * 数据冗余和同步的方案
  * 奔溃后的自动选择方案

## 高可用存储架构

**存储高可用的本质是冗余，其复杂性是同步数据时的一致性问题**（延迟、网络中断导致）。需要注意的是它和业务高可用的区别。

按照单机是否存储所有数据，高可用可以分为以下两种类型：

* 双机模式（单机存储所有的数据）

  | 类型     | 优点 | 缺点 |
  | -------- | ---- | ---- |
  | 主备复制 |      |      |
  | 主从复制 |      |      |
  | 双机切换 |      |      |
  | 主主复制 |      |      |

  其实这个双机集群机制是N机模式的弱化版，两者面对的复杂性都是一样的，只是程度不同而已。需要面对的问题包括：

  * 数据如何复制
  * 主机状态的检测
  * 主机故障后如何选定新主机（paxos、raft等一致性协议）

* 分区（单机不能存储所有的数据）

  感觉就是数据分片到节点，各个节点再做集群。复杂性是数据分片的一般性问题（todo）

## 高可用业务架构

* 防止业务奔溃

  * 负载均衡
  * 限流
  * 熔断

* 奔溃后的方案

  * 业务通常是不带状态的，因此可以简单地用集群中的对等节点取代之。

  * 如果业务也有状态，则将业务的状态委托给存储即可。

总之都可以用k8s搞定

# 复杂度：可扩展架构模式

## 核心思想：

拆！即分层或者模块化，然后针对需要扩展的模块独立修改。

## 各种拆分方式的比较

| 类型     | 例子                         | 优点 | 缺点 |
| -------- | ---------------------------- | ---- | ---- |
| 面向流程 | 分层架构                     |      |      |
| 面向服务 | 微服务、SOA                  |      |      |
| 面向功能 | 微内核（插件机制，规则引擎） |      |      |

以上几种方式可以组合一起使用，对系统的各个维度进行划分，例如：

- 例如用微服务划分系统
- 每个微服务又划分为多个流程
- 每个流程用微内核实现

